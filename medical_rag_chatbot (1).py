
import os
import streamlit as st
import pickle
import pytesseract
from PIL import Image
from langdetect import detect
import pandas as pd
from docx import Document
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_groq import ChatGroq
from gtts import gTTS

INDEX_PATH = "faiss_index.pkl"
EXCEL_PATH = "Book3.xlsx"

# ===== ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Excel =====
def load_drugs_data(excel_path):
    try:
        # Ø´ÙŠØª Ø§Ù„Ø£Ø¯ÙˆÙŠØ©
        drugs_df = pd.read_excel(excel_path, sheet_name="Drugs", header=0)
        drugs_df.columns = drugs_df.columns.str.strip().str.lower()
        drugs_df = drugs_df.loc[:, ~drugs_df.columns.str.contains('^unnamed', case=False)]  # ØªÙ†Ø¸ÙŠÙ Unnamed

        if "drug" not in drugs_df.columns:
            st.error(f"âŒ Ù…ÙÙŠØ´ Ø¹Ù…ÙˆØ¯ 'Drug' ÙÙŠ Ø´ÙŠØª Drugs. Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {drugs_df.columns.tolist()}")
            return None, None, None

        # Ø´ÙŠØª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ù†Ø¨Ø¯Ø£ Ù…Ù† Ø§Ù„ØµÙ Ø§Ù„ØªØ§Ù†ÙŠ)
        keywords_df = pd.read_excel(excel_path, sheet_name="Keywords", header=1)
        keywords_df.columns = keywords_df.columns.str.strip().str.lower()
        keywords_df = keywords_df.loc[:, ~keywords_df.columns.str.contains('^unnamed', case=False)]  # ØªÙ†Ø¸ÙŠÙ Unnamed

        # Ø§Ù„ØªØ£ÙƒØ¯ Ø¥Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©
        if not set(["keyword", "drug"]).issubset(keywords_df.columns):
            st.error(f"âŒ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø´ÙŠØª Keywords. Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù„ÙŠ Ù„Ù‚ÙŠØªÙ‡Ø§: {keywords_df.columns.tolist()}")
            return None, None, None

        # Ù†Ø³Ø®Ø© Ù„Ù„Ø¹Ø±Ø¶
        display_drugs_df = drugs_df.copy()

        # ØªØ¬Ù‡ÙŠØ² Ù„Ù„Ø¨Ø­Ø« (lowercase + strip)
        drugs_df["drug"] = drugs_df["drug"].astype(str).str.strip().str.lower()
        keywords_df["keyword"] = keywords_df["keyword"].astype(str).str.strip().str.lower()
        keywords_df["drug"] = keywords_df["drug"].astype(str).str.strip().str.lower()

        return drugs_df, keywords_df, display_drugs_df

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„: {e}")
        return None, None, None


# ===== Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© =====
def search_in_excel(query, drugs_df, keywords_df):
    query = query.lower().strip()

    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø´ÙŠØª Drugs â†’ ÙŠØ±Ø¬Ù‘Ø¹ ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø¯ÙˆØ§Ø¡
    if drugs_df is not None and "drug" in drugs_df.columns:
        match = drugs_df[drugs_df["drug"].str.contains(query, na=False)]
        if not match.empty:
            return "drug", match

    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø´ÙŠØª Keywords â†’ ÙŠØ±Ø¬Ù‘Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø´ÙŠØª Keywords ÙÙ‚Ø· (Ù…Ù† ØºÙŠØ± keyword)
    if keywords_df is not None and {"keyword", "drug"}.issubset(keywords_df.columns):
        kw_match = keywords_df[keywords_df["keyword"].str.contains(query, na=False)]
        if not kw_match.empty:
            return "keyword", kw_match.drop(columns=["keyword"], errors="ignore")

    return None, None


# ===== ØªØ­Ù…ÙŠÙ„ ÙˆØªÙ‚Ø·ÙŠØ¹ Ù…Ù„ÙØ§Øª PDF Ø§Ù„Ø·Ø¨ÙŠØ© =====
def load_medical_docs(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(docs)

# ===== ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ =====
def embed_documents(docs):
    embed_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    return FAISS.from_documents(docs, embed_model)

# ===== Ø­ÙØ¸ ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª =====
def save_index(index):
    with open(INDEX_PATH, "wb") as f:
        pickle.dump(index, f)

def load_index():
    if os.path.exists(INDEX_PATH):
        with open(INDEX_PATH, "rb") as f:
            return pickle.load(f)
    return None

def update_index(new_docs):
    index = load_index()
    if index:
        index.add_documents(new_docs)
    else:
        index = embed_documents(new_docs)
    save_index(index)
    return index

# ===== Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© =====
def build_qa_system(faiss_index):
    retriever = faiss_index.as_retriever(search_type="similarity", k=4)
    llm = ChatGroq(api_key=os.getenv("GROQ_API_KEY"), model_name="llama3-8b-8192")
    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# ===== Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± =====
def extract_text_from_image(image):
    return pytesseract.image_to_string(image, lang="ara+eng")

# ===== Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù„ØºØ© =====
def detect_language(text):
    try:
        return detect(text)
    except:
        return "unknown"

# ===== ØªØ¨Ø³ÙŠØ· Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© =====
def simplify_prompt(query, lang):
    if lang == "ar":
        return f"Ø¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ø³Ù‡Ù„: {query}"
    elif lang == "en":
        return f"Answer in simple, conversational English: {query}"
    else:
        return query

# ===== Ø¯Ø§Ù„Ø© Ø®Ø§ØµØ© Ù„ÙÙ„ØªØ±Ø© Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù€ LLM =====
def ask_medical_qa(query):
    medical_prompt = f"""
    You are a helpful medical assistant.
    Answer ONLY about drugs, pharmacology, and medical knowledge.
    If the question is unrelated or you don't find info, reply exactly with:
    'âš ï¸ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø·Ø¨ÙŠØ© Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹.'

    Question: {query}
    """
    return st.session_state.qa_chain.run(medical_prompt)

# ===== Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====
def main():
    st.set_page_config(page_title="CHATYMEDx", layout="centered")
    st.markdown("<h1 style='text-align: center; color: #cba37d;'>CHATYMEDx</h1>", unsafe_allow_html=True)

    # ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if "qa_chain" not in st.session_state:
        if os.path.exists(INDEX_PATH):
            index = load_index()
        else:
            with st.spinner("ğŸ“š Embedding default medical file..."):
                docs = load_medical_docs("Clinical Pharmacology - D R Laurence.pdf")
                index = embed_documents(docs)
                save_index(index)
        st.session_state.qa_chain = build_qa_system(index)

    # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ù…Ù† Excel
    drugs_df, keywords_df, display_drugs_df = load_drugs_data(EXCEL_PATH)

    # ===== Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ =====
    with st.sidebar:
        if os.path.exists("Chaty_medx.jpg"):
        st.image("Chaty_medx.jpg", width=100)
        st.markdown("### ğŸ“˜ Upload your PDF")
        pdf_file = st.file_uploader("PDF File", type=["pdf"])
        st.markdown("### ğŸ–¼ï¸ Upload your image:")
        image_file = st.file_uploader("Image", type=["png", "jpg", "jpeg"])

    # ===== Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ù„Ù PDF =====
    if pdf_file:
        with st.spinner("ğŸ“„ Loading and embedding the file..."):
            with open("temp_medical.pdf", "wb") as f:
                f.write(pdf_file.read())
            docs = load_medical_docs("temp_medical.pdf")
            index = update_index(docs)
            st.session_state.qa_chain = build_qa_system(index)
            st.success("âœ… File embedded and added to memory.")

    # ===== Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØµÙˆØ±Ø© =====
    if image_file:
        image = Image.open(image_file)
        st.image(image, caption="The uploaded image", use_container_width=True)
        with st.spinner("ğŸ§  Extracting text from image..."):
            extracted_text = extract_text_from_image(image)
            st.text_area("Extracted text from image:", value=extracted_text, height=150)

    # ===== Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø£Ùˆ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© =====
    query = st.text_input("Write drug name :")

    if query:
        kind, result_df = search_in_excel(query, drugs_df, keywords_df)

        if kind and result_df is not None and not result_df.empty:
            if kind == "drug":
                st.success(f"âœ… Found drug: {query}")
            elif kind == "keyword":
                st.success(f"âœ… Found related drug(s) for your keyword")
            st.dataframe(result_df)  # ÙŠØ¹Ø±Ø¶ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø£Ùˆ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø¨Ø¯ÙˆÙ† keyword ÙˆØ¨Ø¯ÙˆÙ† Unnamed
        else:
            # fallback Ù„Ù„Ù€ QA system
            lang = detect_language(query)
            simplified_query = simplify_prompt(query, lang)
            result = ask_medical_qa(simplified_query)

            if lang == "ar":
                st.markdown(f"<div dir='rtl' style='text-align: right; font-size: 18px;'>{result}</div>", unsafe_allow_html=True)
                st.markdown("<div dir='rtl' style='text-align: right; font-size: 14px; color:gray;'>Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø¯Ù…Ø© Ù„Ø§ ØªÙØ¹ØªØ¨Ø± Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ø¹Ù† Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ©.</div>", unsafe_allow_html=True)
            else:
                st.markdown(f"### Your answer: {result}")
                st.markdown("Note: This service is not a substitute for professional medical advice.")

if __name__ == "__main__":
    main()







