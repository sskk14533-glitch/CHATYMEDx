
import os
import streamlit as st
import pickle
from PIL import Image
import pandas as pd
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms.base import LLM
from langchain.callbacks.manager import CallbackManagerForLLMRun
from gtts import gTTS
import requests
from typing import Optional, List, Any

INDEX_PATH = "chroma_db"  # Ù…Ø¬Ù„Ø¯ Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Chroma
EXCEL_PATH = "Book3.xlsx"

# ===== ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© =====
@st.cache_data
def load_drugs_data(excel_path):
    try:
        drugs_df = pd.read_excel(excel_path, sheet_name="Drugs", header=0)
        drugs_df.columns = drugs_df.columns.str.strip().str.lower()
        keywords_df = pd.read_excel(excel_path, sheet_name="Keywords", header=1)
        keywords_df.columns = keywords_df.columns.str.strip().str.lower()
        display_drugs_df = drugs_df.copy()
        drugs_df["drug"] = drugs_df["drug"].astype(str).str.strip().str.lower()
        keywords_df["keyword"] = keywords_df["keyword"].astype(str).str.strip().str.lower()
        keywords_df["drug"] = keywords_df["drug"].astype(str).str.strip().str.lower()
        return drugs_df, keywords_df, display_drugs_df
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„: {e}")
        return None, None, None

# ===== Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Excel =====
def search_in_excel(query, drugs_df, keywords_df):
    query = query.lower().strip()
    if drugs_df is not None and "drug" in drugs_df.columns:
        match = drugs_df[drugs_df["drug"].str.contains(query, na=False)]
        if not match.empty:
            return "drug", match
    if keywords_df is not None and {"keyword","drug"}.issubset(keywords_df.columns):
        kw_match = keywords_df[keywords_df["keyword"].str.contains(query, na=False)]
        if not kw_match.empty:
            return "keyword", kw_match.drop(columns=["keyword"], errors="ignore")
    return None, None

# ===== ØªØ­Ù…ÙŠÙ„ ÙˆØªÙ‚Ø·ÙŠØ¹ Ù…Ù„ÙØ§Øª PDF =====
def load_medical_docs(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(docs)

# ===== ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ =====
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'}
    )

def embed_documents(docs):
    embed_model = get_embeddings()
    return Chroma.from_documents(docs, embedding=embed_model, persist_directory=INDEX_PATH)

# ===== Ø­ÙØ¸ ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª =====
def save_index(index):
    index.persist()  # Chroma ÙŠØ®Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§

@st.cache_resource
def load_index():
    if os.path.exists(INDEX_PATH):
        return Chroma(persist_directory=INDEX_PATH, embedding_function=get_embeddings())
    return None

def update_index(new_docs):
    index = load_index()
    if index:
        index.add_documents(new_docs)
        index.persist()
    else:
        index = embed_documents(new_docs)
    return index

# ===== Groq LLM Ù…Ø®ØµØµ =====
class GroqLLM(LLM):
    api_key: str
    model_name: str = "llama3-8b-8192"

    @property
    def _llm_type(self) -> str:
        return "groq"

    def _call(self, prompt: str, stop: Optional[List[str]] = None,
              run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any) -> str:
        try:
            headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}
            data = {"messages": [{"role": "user", "content": prompt}],
                    "model": self.model_name, "max_tokens": 500, "temperature": 0.3}
            response = requests.post("https://api.groq.com/openai/v1/chat/completions",
                                     headers=headers, json=data, timeout=30)
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                return "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Groq API"
        except Exception as e:
            return f"âš ï¸ Ø®Ø·Ø£: {str(e)}"

# ===== Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© =====
@st.cache_resource
def build_qa_system(chroma_index):
    retriever = chroma_index.as_retriever(search_type="similarity", k=4)
    groq_api_key = os.getenv("GROQ_API_KEY")
    if not groq_api_key:
        st.error("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© GROQ_API_KEY ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©")
        return None
    llm = GroqLLM(api_key=groq_api_key)
    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# ===== Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====
def main():
    st.set_page_config(page_title="CHATYMEDx", layout="centered")
    st.markdown("<h1 style='text-align: center; color: #cba37d;'>CHATYMEDx</h1>", unsafe_allow_html=True)

    # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ù…Ù† Excel
    if os.path.exists(EXCEL_PATH):
        drugs_df, keywords_df, display_drugs_df = load_drugs_data(EXCEL_PATH)
    else:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Excel.")
        drugs_df, keywords_df, display_drugs_df = None, None, None

    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
    with st.sidebar:
        st.markdown("### ğŸ“˜ Upload your PDF")
        pdf_file = st.file_uploader("PDF File", type=["pdf"])
        st.markdown("### ğŸ–¼ï¸ Upload your image:")
        image_file = st.file_uploader("Image", type=["png", "jpg", "jpeg"])

    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ PDF
    if pdf_file:
        with st.spinner("ğŸ“„ Loading and embedding the file..."):
            with open("temp_medical.pdf", "wb") as f:
                f.write(pdf_file.read())
            docs = load_medical_docs("temp_medical.pdf")
            index = update_index(docs)
            st.session_state.qa_chain = build_qa_system(index)
            st.success("âœ… File embedded and added to memory.")

    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØµÙˆØ±Ø© (Ù…ÙŠØ²Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ø¹Ø·Ù„Ø©)
    if image_file:
        image = Image.open(image_file)
        st.image(image, caption="The uploaded image", use_container_width=True)
        st.info("ğŸ“ Ù…ÙŠØ²Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø³ØªÙƒÙˆÙ† Ù…ØªØ§Ø­Ø© Ù‚Ø±ÙŠØ¨Ø§Ù‹")

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø£Ùˆ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ©
    query = st.text_input("Write drug name:")
    if query:
        if drugs_df is not None and keywords_df is not None:
            kind, result_df = search_in_excel(query, drugs_df, keywords_df)
            if kind and result_df is not None and not result_df.empty:
                if kind == "drug":
                    st.success(f"âœ… Found drug: {query}")
                else:
                    st.success(f"âœ… Found related drug(s) for your keyword")
                st.dataframe(result_df)
            else:
                if "qa_chain" in st.session_state:
                    result = st.session_state.qa_chain.run(query)
                    st.markdown(f"### Your answer: {result}")
                else:
                    st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù PDF Ø·Ø¨ÙŠ Ø£ÙˆÙ„Ø§Ù‹ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© GROQ_API_KEY.")

if __name__ == "__main__":
    main()


