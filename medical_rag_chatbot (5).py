import os
import streamlit as st
import pickle
from PIL import Image
from langdetect import detect
import pandas as pd
from docx import Document
import tempfile
import io

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    st.warning("âš ï¸ Tesseract ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø®Ø§ØµÙŠØ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ù…Ø¹Ø·Ù„Ø©")

try:
    from langchain.vectorstores import FAISS
    from langchain.embeddings import HuggingFaceEmbeddings
    from langchain.chains import RetrievalQA
    from langchain.document_loaders import PyPDFLoader
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_groq import ChatGroq
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    st.error("âŒ Ù…ÙƒØªØ¨Ø§Øª LangChain ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")

try:
    from gtts import gTTS
    GTTS_AVAILABLE = True
except ImportError:
    GTTS_AVAILABLE = False

INDEX_PATH = "faiss_index.pkl"
EXCEL_PATH = "Book3.xlsx"

# ===== ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Excel =====
def load_drugs_data(excel_path):
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
        if not os.path.exists(excel_path):
            st.warning(f"âš ï¸ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„ {excel_path} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            return None, None, None
            
        drugs_df = pd.read_excel(excel_path, sheet_name="Drugs", header=0)
        drugs_df.columns = drugs_df.columns.str.strip().str.lower()
        drugs_df = drugs_df.loc[:, ~drugs_df.columns.str.contains('^unnamed', case=False)]

        if "drug" not in drugs_df.columns:
            st.error(f"âŒ Ù…ÙÙŠØ´ Ø¹Ù…ÙˆØ¯ 'Drug' ÙÙŠ Ø´ÙŠØª Drugs. Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {drugs_df.columns.tolist()}")
            return None, None, None

        keywords_df = pd.read_excel(excel_path, sheet_name="Keywords", header=1)
        keywords_df.columns = keywords_df.columns.str.strip().str.lower()
        keywords_df = keywords_df.loc[:, ~keywords_df.columns.str.contains('^unnamed', case=False)]

        if not set(["keyword", "drug"]).issubset(keywords_df.columns):
            st.error(f"âŒ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø´ÙŠØª Keywords. Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù„ÙŠ Ù„Ù‚ÙŠØªÙ‡Ø§: {keywords_df.columns.tolist()}")
            return None, None, None

        display_drugs_df = drugs_df.copy()

        drugs_df["drug"] = drugs_df["drug"].astype(str).str.strip().str.lower()
        keywords_df["keyword"] = keywords_df["keyword"].astype(str).str.strip().str.lower()
        keywords_df["drug"] = keywords_df["drug"].astype(str).str.strip().str.lower()

        return drugs_df, keywords_df, display_drugs_df

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³ÙŠÙ„: {e}")
        return None, None, None


# ===== Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© =====
def search_in_excel(query, drugs_df, keywords_df):
    query = query.lower().strip()

    if drugs_df is not None and "drug" in drugs_df.columns:
        match = drugs_df[drugs_df["drug"].str.contains(query, na=False)]
        if not match.empty:
            return "drug", match

    if keywords_df is not None and {"keyword", "drug"}.issubset(keywords_df.columns):
        kw_match = keywords_df[keywords_df["keyword"].str.contains(query, na=False)]
        if not kw_match.empty:
            return "keyword", kw_match.drop(columns=["keyword"], errors="ignore")

    return None, None


# ===== ØªØ­Ù…ÙŠÙ„ ÙˆØªÙ‚Ø·ÙŠØ¹ Ù…Ù„ÙØ§Øª PDF Ø§Ù„Ø·Ø¨ÙŠØ© =====
def load_medical_docs(file_path):
    if not LANGCHAIN_AVAILABLE:
        st.error("âŒ LangChain ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© PDF")
        return []
    
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        return splitter.split_documents(docs)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ PDF: {e}")
        return []


# ===== ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ =====
def embed_documents(docs):
    if not LANGCHAIN_AVAILABLE:
        st.error("âŒ LangChain ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„Ù„ØªØ¶Ù…ÙŠÙ†")
        return None
        
    try:
        embed_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            model_kwargs={'device': 'cpu'}
        )
        return FAISS.from_documents(docs, embed_model)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¶Ù…ÙŠÙ†: {e}")
        return None


# ===== Ø­ÙØ¸ ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª =====
def save_index(index):
    try:
        with open(INDEX_PATH, "wb") as f:
            pickle.dump(index, f)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ÙÙ‡Ø±Ø³: {e}")


def load_index():
    try:
        if os.path.exists(INDEX_PATH):
            with open(INDEX_PATH, "rb") as f:
                return pickle.load(f)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³: {e}")
    return None


def update_index(new_docs):
    if not new_docs:
        return None
        
    try:
        index = load_index()
        if index:
            index.add_documents(new_docs)
        else:
            index = embed_documents(new_docs)
        if index:
            save_index(index)
        return index
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙ‡Ø±Ø³: {e}")
        return None


# ===== Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© =====
def build_qa_system(faiss_index):
    if not LANGCHAIN_AVAILABLE:
        st.error("âŒ LangChain ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„Ù†Ø¸Ø§Ù… QA")
        return None
        
    try:
        retriever = faiss_index.as_retriever(search_type="similarity", k=4)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ API key
        if "GROQ_API_KEY" not in st.secrets:
            st.error("âŒ GROQ_API_KEY Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ secrets")
            return None
            
        api_key = st.secrets["GROQ_API_KEY"]

        llm = ChatGroq(
            api_key=api_key,
            model_name="llama3-8b-8192"
        )

        return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… QA: {e}")
        return None


# ===== Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± =====
def extract_text_from_image(image):
    if not TESSERACT_AVAILABLE:
        st.warning("âš ï¸ Tesseract ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±")
        return "Ø®Ø§ØµÙŠØ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© Ø­Ø§Ù„ÙŠØ§"
    
    try:
        return pytesseract.image_to_string(image, lang="ara+eng")
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {e}")
        return "ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©"


# ===== Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù„ØºØ© =====
def detect_language(text):
    try:
        return detect(text)
    except:
        return "unknown"


# ===== ØªØ¨Ø³ÙŠØ· Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© =====
def simplify_prompt(query, lang):
    if lang == "ar":
        return f"Ø¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ø³Ù‡Ù„: {query}"
    elif lang == "en":
        return f"Answer in simple, conversational English: {query}"
    else:
        return query


# ===== Ø¯Ø§Ù„Ø© Ø®Ø§ØµØ© Ù„ÙÙ„ØªØ±Ø© Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù€ LLM =====
def ask_medical_qa(query):
    if "qa_chain" not in st.session_state or st.session_state.qa_chain is None:
        return "âš ï¸ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø© ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§"
        
    try:
        medical_prompt = f"""
        You are a helpful medical assistant.
        Answer ONLY about drugs, pharmacology, and medical knowledge.
        If the question is unrelated or you don't find info, reply exactly with:
        'âš ï¸ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø·Ø¨ÙŠØ© Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹.'

        Question: {query}
        """
        return st.session_state.qa_chain.run(medical_prompt)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {e}")
        return "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«"


# ===== Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ =====
def main():
    st.set_page_config(page_title="CHATYMEDx", layout="centered")
    st.markdown("<h1 style='text-align: center; color: #cba37d;'>CHATYMEDx</h1>", unsafe_allow_html=True)

    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… QA Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯
    if "qa_chain" not in st.session_state:
        st.session_state.qa_chain = None
        
        if LANGCHAIN_AVAILABLE:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù PDF Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
            default_pdf = "Clinical Pharmacology - D R Laurence.pdf"
            if os.path.exists(INDEX_PATH):
                index = load_index()
                if index:
                    st.session_state.qa_chain = build_qa_system(index)
            elif os.path.exists(default_pdf):
                with st.spinner("ğŸ“š Embedding default medical file..."):
                    docs = load_medical_docs(default_pdf)
                    if docs:
                        index = embed_documents(docs)
                        if index:
                            save_index(index)
                            st.session_state.qa_chain = build_qa_system(index)

    # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ©
    drugs_df, keywords_df, display_drugs_df = load_drugs_data(EXCEL_PATH)

    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        logo_path = "Chaty_medx.jpg"
        if os.path.exists(logo_path):
            st.image(logo_path, width=100)
        else:
            st.info("ğŸ’¡ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¶Ø§ÙØ© logo Ø¨Ø§Ù„Ø§Ø³Ù… 'Chaty_medx.jpg'")

        st.markdown("### ğŸ“˜ Upload your PDF")
        pdf_file = st.file_uploader("PDF File", type=["pdf"])

        st.markdown("### ğŸ–¼ï¸ Upload your image:")
        image_file = st.file_uploader("Image", type=["png", "jpg", "jpeg"])

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±ÙØ¹ PDF
    if pdf_file and LANGCHAIN_AVAILABLE:
        with st.spinner("ğŸ“„ Loading and embedding the file..."):
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… tempfile Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù…Ø¤Ù‚Øª Ø¢Ù…Ù†
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                    tmp_file.write(pdf_file.read())
                    tmp_path = tmp_file.name
                
                docs = load_medical_docs(tmp_path)
                if docs:
                    index = update_index(docs)
                    if index:
                        st.session_state.qa_chain = build_qa_system(index)
                        st.success("âœ… File embedded and added to memory.")
                    else:
                        st.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³")
                else:
                    st.error("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª")
                
                # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                os.unlink(tmp_path)
                
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© PDF: {e}")

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±
    if image_file:
        try:
            image = Image.open(image_file)
            st.image(image, caption="The uploaded image", use_container_width=True)
            
            if TESSERACT_AVAILABLE:
                with st.spinner("ğŸ§  Extracting text from image..."):
                    extracted_text = extract_text_from_image(image)
                    st.text_area("Extracted text from image:", value=extracted_text, height=150)
            else:
                st.warning("âš ï¸ Ø®Ø§ØµÙŠØ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")

    # Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    query = st.text_input("Write drug name:")

    if query:
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø£ÙˆÙ„Ø§
        kind, result_df = search_in_excel(query, drugs_df, keywords_df)

        if kind and result_df is not None and not result_df.empty:
            if kind == "drug":
                st.success(f"âœ… Found drug: {query}")
            elif kind == "keyword":
                st.success(f"âœ… Found related drug(s) for your keyword")
            st.dataframe(result_df)
        else:
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ ÙÙŠ Ø§Ù„Ø£Ø¯ÙˆÙŠØ©ØŒ Ù†Ø¨Ø­Ø« Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI
            if LANGCHAIN_AVAILABLE and st.session_state.qa_chain:
                lang = detect_language(query)
                simplified_query = simplify_prompt(query, lang)
                result = ask_medical_qa(simplified_query)

                if lang == "ar":
                    st.markdown(f"<div dir='rtl' style='text-align: right; font-size: 18px;'>{result}</div>", unsafe_allow_html=True)
                    st.markdown("<div dir='rtl' style='text-align: right; font-size: 14px; color:gray;'>Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø¯Ù…Ø© Ù„Ø§ ØªÙØ¹ØªØ¨Ø± Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ø¹Ù† Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±Ø© Ø§Ù„Ø·Ø¨ÙŠØ©.</div>", unsafe_allow_html=True)
                else:
                    st.markdown(f"### Your answer: {result}")
                    st.markdown("Note: This service is not a substitute for professional medical advice.")
            else:
                st.warning("âš ï¸ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§")

    # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    with st.expander("â„¹ï¸ System Status"):
        st.write(f"ğŸ”§ LangChain Available: {LANGCHAIN_AVAILABLE}")
        st.write(f"ğŸ“· Tesseract Available: {TESSERACT_AVAILABLE}")
        st.write(f"ğŸ”Š gTTS Available: {GTTS_AVAILABLE}")
        st.write(f"ğŸ—ƒï¸ Excel Data Available: {drugs_df is not None}")
        st.write(f"ğŸ¤– QA System Ready: {st.session_state.qa_chain is not None}")


if __name__ == "__main__":
    main()



